{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr5RmQWa4owcjZjvypaY6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravetivanaja/Major-project-/blob/main/Internshala2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwyk657VC1qW",
        "outputId": "8c7b6863-8a39-4520-ae5e-7da879873326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1...\n",
            "Scraping page 2...\n",
            "Scraping page 3...\n",
            "Scraping page 4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-172420949476>:65: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  asin = product_soup.find(\"th\", text=\"ASIN\")\n",
            "<ipython-input-1-172420949476>:73: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  manufacturer = product_soup.find(\"th\", text=\"Manufacturer\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 5...\n",
            "Scraping page 6...\n",
            "Scraping page 7...\n",
            "Scraping page 8...\n",
            "Scraping page 9...\n",
            "Scraping page 10...\n",
            "Scraping page 11...\n",
            "Scraping page 12...\n",
            "Scraping page 13...\n",
            "Scraping page 14...\n",
            "Scraping page 15...\n",
            "Scraping page 16...\n",
            "Scraping page 17...\n",
            "Scraping page 18...\n",
            "Scraping page 19...\n",
            "Scraping page 20...\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Set the URL of the product listing page\n",
        "base_url = \"https://www.amazon.in/s\"\n",
        "params = {\n",
        "    \"k\": \"bags\",\n",
        "    \"crid\": \"2M096C61O4MLT\",\n",
        "    \"qid\": \"1653308124\",\n",
        "    \"sprefix\": \"ba%2Caps%2C283\",\n",
        "    \"ref\": \"sr_pg_1\"\n",
        "}\n",
        "\n",
        "# Scrape 20 pages\n",
        "all_data = []\n",
        "for page in range(1, 21):\n",
        "    print(f\"Scraping page {page}...\")\n",
        "\n",
        "    params[\"ref\"] = f\"sr_pg_{page}\"\n",
        "    response = requests.get(base_url, params=params)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find the product containers\n",
        "    products = soup.find_all(\"div\", class_=\"sg-col-inner\")\n",
        "\n",
        "    # Extract the required information from each product\n",
        "    for product in products:\n",
        "        data = {}\n",
        "\n",
        "        # Product URL\n",
        "        url = product.find(\"a\", class_=\"a-link-normal\")\n",
        "        if url:\n",
        "            data[\"Product URL\"] = \"https://www.amazon.in\" + url[\"href\"]\n",
        "        else:\n",
        "            data[\"Product URL\"] = \"N/A\"\n",
        "\n",
        "        # Product Name\n",
        "        name = product.find(\"span\", class_=\"a-size-medium\")\n",
        "        data[\"Product Name\"] = name.text.strip() if name else \"N/A\"\n",
        "\n",
        "        # Product Price\n",
        "        price = product.find(\"span\", class_=\"a-offscreen\")\n",
        "        data[\"Product Price\"] = price.text.strip() if price else \"N/A\"\n",
        "\n",
        "        # Rating\n",
        "        rating = product.find(\"span\", class_=\"a-icon-alt\")\n",
        "        data[\"Rating\"] = rating.text.strip() if rating else \"N/A\"\n",
        "\n",
        "        # Number of reviews\n",
        "        reviews = product.find(\"span\", class_=\"a-size-base\")\n",
        "        data[\"Number of Reviews\"] = reviews.text.strip() if reviews else \"N/A\"\n",
        "\n",
        "        # Fetch additional information from product URL\n",
        "        product_url = data[\"Product URL\"]\n",
        "        if product_url != \"N/A\":\n",
        "            product_response = requests.get(product_url)\n",
        "            product_soup = BeautifulSoup(product_response.content, \"html.parser\")\n",
        "\n",
        "            # Description\n",
        "            description = product_soup.find(\"div\", id=\"feature-bullets\")\n",
        "            data[\"Description\"] = description.get_text(\"\\n\").strip() if description else \"N/A\"\n",
        "\n",
        "            # ASIN\n",
        "            asin = product_soup.find(\"th\", text=\"ASIN\")\n",
        "            data[\"ASIN\"] = asin.find_next(\"td\").get_text(strip=True) if asin else \"N/A\"\n",
        "\n",
        "            # Product Description\n",
        "            product_desc = product_soup.find(\"div\", id=\"productDescription\")\n",
        "            data[\"Product Description\"] = product_desc.get_text(\"\\n\").strip() if product_desc else \"N/A\"\n",
        "\n",
        "            # Manufacturer\n",
        "            manufacturer = product_soup.find(\"th\", text=\"Manufacturer\")\n",
        "            data[\"Manufacturer\"] = manufacturer.find_next(\"td\").get_text(strip=True) if manufacturer else \"N/A\"\n",
        "\n",
        "        all_data.append(data)\n",
        "\n",
        "# Create a DataFrame and export data to CSV\n",
        "df = pd.DataFrame(all_data)\n",
        "df.to_csv(\"product_data.csv\", index=False)"
      ]
    }
  ]
}